{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.ticker as mtick\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests     \n",
    "import shutil       \n",
    "import datetime\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import requests\n",
    "import json\n",
    "from random import randint\n",
    "import  random\n",
    "import os\n",
    "os.chdir('C:/Users/Travis/OneDrive/Data Science/Personal_Projects/Sports/UFC_Prediction_V2')\n",
    "from cmath import nan\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "import pickle\n",
    "from sklearn.metrics import fbeta_score\n",
    "import winsound\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_date_from_ufcstats(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    date = soup.find('li', class_='b-list__box-list-item').text\n",
    "    date = date.replace('\\n', '')\n",
    "    ed = date.find(':')\n",
    "    date = date[ed+2:].strip()\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_from_ufcstats(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    details = soup.find('div', class_='b-fight-details__content').text\n",
    "    details = details.replace('\\n', '')\n",
    "    deet = details.find('Details:')\n",
    "    details = details[deet+8:].strip()\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_title_from_ufcstats(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    title = soup.find('h2', class_='b-content__title').text\n",
    "    title = title.replace('\\n', '').strip()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_url_from_ufcstats(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    title = soup.find('h2', class_='b-content__title')\n",
    "    title = title.find('a')\n",
    "    title = title['href']\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fight_urls(urls):\n",
    "\n",
    "    # get links to all fights on each event page\n",
    "\n",
    "    links = pd.DataFrame()\n",
    "    for u in urls:\n",
    "        try:\n",
    "            reqs = requests.get(u)\n",
    "            soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "            title = soup.find('h2', class_='b-content__title').text\n",
    "            title = title.replace('\\n', '')\n",
    "            date = soup.find('li', class_='b-list__box-list-item').text\n",
    "            d = date.find('Date:')\n",
    "            date = date[d+6:].replace('\\n', '')\n",
    "            for link in soup.find_all('a'):\n",
    "                # append url and event title to df\n",
    "                if 'fight-details' in link.get('href'):\n",
    "                    links = links.append({'Fight_url': link.get('href'), 'Event_title': title, 'Date' : date}, ignore_index=True)\n",
    "\n",
    "        except:\n",
    "            return 'No Fighties'\n",
    "            \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winner_from_ufcstats(url):\n",
    "\n",
    "    ### This function scrapes the UFCStats website for the winner of a given fight###\n",
    "\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        both = soup.find_all('div', class_='b-fight-details__person')\n",
    "        first = both[0].text.replace('   ', '').replace('\\n', '').strip()\n",
    "        second = both[1].text.replace('   ', '').replace('\\n', '').strip()\n",
    "        if(first.startswith('W')):\n",
    "            winner = first[3:]\n",
    "        else:\n",
    "            winner = second[3:]\n",
    "        return winner\n",
    "        \n",
    "    except:\n",
    "        return nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_date_from_ufcstats(url):\n",
    "    ### This function scrapes the UFCStats website for the event date of a given fight ###\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        date = soup.find('li', class_='b-list__box-list-item').text\n",
    "        date = date.replace('\\n', '')\n",
    "        ed = date.find(':')\n",
    "        date = date[ed+2:].strip()\n",
    "        return date\n",
    "    except:\n",
    "        return nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_details(event_id):\n",
    "    # This function scrapes event details from ufc stats\n",
    "\n",
    "    #try:\n",
    "        df = pd.read_html('http://www.ufcstats.com/event-details/' + event_id)\n",
    "        df = df[0]\n",
    "        # split by space and get third element\n",
    "        df['Fighter1'] = df['Fighter'].str.split('  ').str[0]\n",
    "        df['Fighter2'] = df['Fighter'].str.split('  ').str[1]\n",
    "        # fix Kd\n",
    "        df['F1_Kd'] = df['Kd'].str.split('  ').str[0]\n",
    "        df['F2_Kd'] = df['Kd'].str.split('  ').str[1]\n",
    "        # fix Str\n",
    "        df['F1_Str'] = df['Str'].str.split('  ').str[0]\n",
    "        df['F2_Str'] = df['Str'].str.split('  ').str[1]\n",
    "        # fix Td\n",
    "        df['F1_Td'] = df['Td'].str.split('  ').str[0]\n",
    "        df['F2_Td'] = df['Td'].str.split('  ').str[1]\n",
    "        # fix Sub\n",
    "        df['F1_Sub'] = df['Sub'].str.split('  ').str[0]\n",
    "        df['F2_Sub'] = df['Sub'].str.split('  ').str[1]\n",
    "\n",
    "        badcols = ['Fighter', 'Kd', 'Str', 'Td', 'Sub']\n",
    "\n",
    "        # save index+1 to new column called \"fight_num\"\n",
    "        df['fight_num'] = df.index + 1\n",
    "        df['event_id'] = event_id\n",
    "\n",
    "        # get fight links\n",
    "        page = requests.get('http://www.ufcstats.com/event-details/' + event_id)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        fight_linkies = soup.find_all('a')\n",
    "        fight_links = [n['href'] for n in fight_linkies]\n",
    "        fight_links = [n for n in fight_links if 'fight-details' in n]\n",
    "        # delete duplicate links\n",
    "        fight_links2 = pd.DataFrame(fight_links)\n",
    "        fight_links2 = fight_links2.drop_duplicates()\n",
    "        fight_links = fight_links2[0].tolist()\n",
    "\n",
    "        # append fight links to df\n",
    "        df['fight_link'] = fight_links\n",
    "\n",
    "        df = df.drop(badcols, axis=1)\n",
    "        df.to_csv('data/ufc_stats/events2/'+ event_id +'.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fight_totals(fight_details_url):\n",
    "    # function returns the fight totals for a given fightid\n",
    "    da_url = fight_details_url\n",
    "    fightid = da_url[da_url.find('fight-details/')+14:]\n",
    "    df = pd.read_html(da_url)\n",
    "    # Part 1: Total Fight Stats\n",
    "    totals = df[0]\n",
    "    # replace '---' with 0\n",
    "    for col in totals.columns:\n",
    "        totals[col] = totals[col].astype(str).replace({'---': 0})\n",
    "        totals[col] = totals[col].astype(str).replace({'--': 0})\n",
    "\n",
    "\n",
    "    totals['Fighter_A'] = totals['Fighter'].str.split(' ').str[0] + ' ' + totals['Fighter'].str.split(' ').str[1]\n",
    "    totals['Fighter_B'] = totals['Fighter'].str.split(' ').str[2] + ' ' + totals['Fighter'].str.split(' ').str[3]\n",
    "    totals['A_Kd'] = totals['KD'].str.split('  ').str[0]\n",
    "    totals['B_Kd'] = totals['KD'].str.split('  ').str[1]\n",
    "    totals['A_Sig_strike'] = totals['Sig. str.'].str.split('  ').str[0]\n",
    "    totals['B_Sig_strike'] = totals['Sig. str.'].str.split('  ').str[1]\n",
    "    # split sig strikes into landed and attempted\n",
    "    totals['A_Sig_strike_land'] = totals['A_Sig_strike'].str.split(' of ').str[0]\n",
    "    totals['A_Sig_strike_att'] = totals['A_Sig_strike'].str.split(' of ').str[1]\n",
    "    totals['B_Sig_strike_land'] = totals['B_Sig_strike'].str.split(' of ').str[0]\n",
    "    totals['B_Sig_strike_att'] = totals['B_Sig_strike'].str.split(' of ').str[1]\n",
    "    # change to numeric\n",
    "    totals['A_Sig_strike_land'].replace({'---', 0}, inplace=True)\n",
    "    totals['A_Sig_strike_att'].replace({'---', 0}, inplace=True)\n",
    "    totals['B_Sig_strike_land'].replace({'---', 0}, inplace=True)\n",
    "    totals['B_Sig_strike_att'].replace({'---', 0}, inplace=True)\n",
    "\n",
    "    totals['A_Sig_strike_land'] = pd.to_numeric(totals['A_Sig_strike_land'])\n",
    "    totals['A_Sig_strike_att'] = pd.to_numeric(totals['A_Sig_strike_att'])\n",
    "    totals['B_Sig_strike_land'] = pd.to_numeric(totals['B_Sig_strike_land'])\n",
    "    totals['B_Sig_strike_att'] = pd.to_numeric(totals['B_Sig_strike_att'])\n",
    "\n",
    "    totals['A_Sig_strike_percent'] = totals['Sig. str. %'].str.split('  ').str[0]\n",
    "    totals['B_Sig_strike_percent'] = totals['Sig. str. %'].str.split('  ').str[1]\n",
    "    # get rid of % sign\n",
    "    totals['A_Sig_strike_percent'] = totals['A_Sig_strike_percent'].str.replace('%', '')\n",
    "    totals['B_Sig_strike_percent'] = totals['B_Sig_strike_percent'].str.replace('%', '')\n",
    "\n",
    "    totals['A_Sig_strike_percent'] = totals['A_Sig_strike_percent'].astype(str).replace({'---': 0})\n",
    "    totals['B_Sig_strike_percent'] = totals['B_Sig_strike_percent'].astype(str).replace({'---': 0})\n",
    "    # change to numeric\n",
    "    totals['A_Sig_strike_percent'] = pd.to_numeric(totals['A_Sig_strike_percent'])/100\n",
    "    totals['B_Sig_strike_percent'] = pd.to_numeric(totals['B_Sig_strike_percent'])/100\n",
    "    # total strikes\n",
    "    totals['A_Total_Strikes'] = totals['Total str.'].str.split('  ').str[0]\n",
    "    totals['B_Total_Strikes'] = totals['Total str.'].str.split('  ').str[1]\n",
    "    # split total strikes into landed and attempted\n",
    "    totals['A_Total_Strikes_land'] = totals['A_Total_Strikes'].str.split(' of ').str[0]\n",
    "    totals['A_Total_Strikes_att'] = totals['A_Total_Strikes'].str.split(' of ').str[1]\n",
    "    totals['B_Total_Strikes_land'] = totals['B_Total_Strikes'].str.split(' of ').str[0]\n",
    "    totals['B_Total_Strikes_att'] = totals['B_Total_Strikes'].str.split(' of ').str[1]\n",
    "\n",
    "    totals['A_Total_Strikes_land'].replace({'---',0}, inplace=True)\n",
    "    totals['A_Total_Strikes_att'].replace({'---',0}, inplace=True)\n",
    "    totals['B_Total_Strikes_land'].replace({'---',0}, inplace=True)\n",
    "    totals['B_Total_Strikes_att'].replace({'---',0}, inplace=True)\n",
    "    # change to numeric\n",
    "    totals['A_Total_Strikes_land'] = pd.to_numeric(totals['A_Total_Strikes_land'])\n",
    "    totals['A_Total_Strikes_att'] = pd.to_numeric(totals['A_Total_Strikes_att'])\n",
    "    totals['B_Total_Strikes_land'] = pd.to_numeric(totals['B_Total_Strikes_land'])\n",
    "    totals['B_Total_Strikes_att'] = pd.to_numeric(totals['B_Total_Strikes_att'])\n",
    "\n",
    "    totals['A_Total_Strikes_land'].astype(str).replace({'---',0}, inplace=True)\n",
    "    totals['A_Total_Strikes_att'].astype(str).replace({'---',0}, inplace=True)\n",
    "    totals['B_Total_Strikes_land'].astype(str).replace({'---',0}, inplace=True)\n",
    "    totals['B_Total_Strikes_att'].astype(str).replace({'---',0}, inplace=True) \n",
    "\n",
    "    # calculate total strike percentage\n",
    "    totals['A_Total_Strikes_percent'] = totals['A_Total_Strikes_land'] / totals['A_Total_Strikes_att']\n",
    "    totals['B_Total_Strikes_percent'] = totals['B_Total_Strikes_land'] / totals['B_Total_Strikes_att']\n",
    "    # takedown stats\n",
    "    totals['A_Takedowns'] = totals['Td'].str.split('  ').str[0]\n",
    "    totals['B_Takedowns'] = totals['Td'].str.split('  ').str[1]\n",
    "    # split takedowns into landed and attempted\n",
    "    totals['A_Takedowns_land'] = totals['A_Takedowns'].str.split(' of ').str[0]\n",
    "    totals['A_Takedowns_att'] = totals['A_Takedowns'].str.split(' of ').str[1]\n",
    "    totals['B_Takedowns_land'] = totals['B_Takedowns'].str.split(' of ').str[0]\n",
    "    totals['B_Takedowns_att'] = totals['B_Takedowns'].str.split(' of ').str[1]\n",
    "    # change to numeric\n",
    "    totals['A_Takedowns_land'] = pd.to_numeric(totals['A_Takedowns_land'])\n",
    "    totals['A_Takedowns_att'] = pd.to_numeric(totals['A_Takedowns_att'])\n",
    "    totals['B_Takedowns_land'] = pd.to_numeric(totals['B_Takedowns_land'])\n",
    "    totals['B_Takedowns_att'] = pd.to_numeric(totals['B_Takedowns_att'])\n",
    "    # fix %\n",
    "    totals['Td %'].replace({'---': 0}, inplace=True)\n",
    "    # get rid of ---\n",
    "    totals['A_Takedowns_land'].replace({'---': 0}, inplace=True)\n",
    "    totals['A_Takedowns_att'].replace({'---': 0}, inplace=True)\n",
    "    totals['B_Takedowns_land'].replace({'---': 0}, inplace=True)\n",
    "    totals['B_Takedowns_att'].replace({'---': 0}, inplace=True)\n",
    "    totals['A_Takedown_percent'] = totals['A_Takedowns_land'] / totals['A_Takedowns_att']\n",
    "    totals['B_Takedown_percent'] = totals['B_Takedowns_land'] / totals['B_Takedowns_att']\n",
    "    # submission attempts\n",
    "    totals['A_Sub_Attempts'] = totals['Sub. att'].str.split('  ').str[0]\n",
    "    totals['B_Sub_Attempts'] = totals['Sub. att'].str.split('  ').str[1]\n",
    "    # split submission attempts into landed and attempted\n",
    "    totals['A_Sub_Attempts_land'] = totals['A_Sub_Attempts'].str.split(' of ').str[0]\n",
    "    totals['A_Sub_Attempts_att'] = totals['A_Sub_Attempts'].str.split(' of ').str[1]\n",
    "    totals['B_Sub_Attempts_land'] = totals['B_Sub_Attempts'].str.split(' of ').str[0]\n",
    "    totals['B_Sub_Attempts_att'] = totals['B_Sub_Attempts'].str.split(' of ').str[1]\n",
    "    # change to numeric\n",
    "    totals['A_Sub_Attempts_land'] = pd.to_numeric(totals['A_Sub_Attempts_land'])\n",
    "    totals['A_Sub_Attempts_att'] = pd.to_numeric(totals['A_Sub_Attempts_att'])\n",
    "    totals['B_Sub_Attempts_land'] = pd.to_numeric(totals['B_Sub_Attempts_land'])\n",
    "    totals['B_Sub_Attempts_att'] = pd.to_numeric(totals['B_Sub_Attempts_att'])\n",
    "    # Rev\n",
    "    totals['A_Rev'] = totals['Rev.'].str.split('  ').str[0]\n",
    "    totals['B_Rev'] = totals['Rev.'].str.split('  ').str[1]\n",
    "    # change to numeric\n",
    "    totals['A_Rev'] = pd.to_numeric(totals['A_Rev'])\n",
    "    totals['B_Rev'] = pd.to_numeric(totals['B_Rev'])\n",
    "    # control time\n",
    "    totals['A_Ctrl_time'] = totals['Ctrl'].str.split('  ').str[0]\n",
    "    totals['B_Ctrl_time'] = totals['Ctrl'].str.split('  ').str[1]\n",
    "    \n",
    "\n",
    "    # split control time into minutes and seconds, and then convert to seconds\n",
    "    totals['A_Ctrl_time_min'] = totals['A_Ctrl_time'].str.split(':').str[0]\n",
    "    totals['A_Ctrl_time_sec'] = totals['A_Ctrl_time'].str.split(':').str[1]\n",
    "    totals['B_Ctrl_time_min'] = totals['B_Ctrl_time'].str.split(':').str[0]\n",
    "    totals['B_Ctrl_time_sec'] = totals['B_Ctrl_time'].str.split(':').str[1]\n",
    "\n",
    "    totals['A_Ctrl_time_min'] = totals['A_Ctrl_time_min'].replace({'--': 0})\n",
    "    totals['A_Ctrl_time_sec'] = totals['A_Ctrl_time_sec'].replace({'--': 0})\n",
    "    totals['B_Ctrl_time_min'] = totals['B_Ctrl_time_min'].replace({'--': 0})\n",
    "    totals['B_Ctrl_time_sec'] = totals['B_Ctrl_time_sec'].replace({'--': 0})\n",
    "\n",
    "    # convert to seconds\n",
    "    totals['A_Ctrl_time_tot'] = pd.to_numeric(totals['A_Ctrl_time_min']) * 60 + pd.to_numeric(totals['A_Ctrl_time_sec'])\n",
    "    totals['B_Ctrl_time_tot'] = pd.to_numeric(totals['B_Ctrl_time_min']) * 60 + pd.to_numeric(totals['B_Ctrl_time_sec'])\n",
    "\n",
    "\n",
    "    # add date with beatufil soup\n",
    "    totals['details'] = get_details_from_ufcstats(da_url)\n",
    "    totals['event_title'] = get_event_title_from_ufcstats(da_url)\n",
    "    event_url = get_event_url_from_ufcstats(da_url)\n",
    "    totals['event_url'] = event_url\n",
    "    totals['date'] = get_event_date_from_ufcstats(event_url)\n",
    "\n",
    "    try:\n",
    "        totals['Winner']= get_winner_from_ufcstats(da_url)\n",
    "    except:\n",
    "        totals['Winner']= nan\n",
    "\n",
    "    bad_cols = ['Fighter', 'KD', 'Sig. str. %', 'Sig. str.', 'Total str.', 'Td', 'Td %', 'Sub. att', \n",
    "                'Rev.', 'Ctrl', 'A_Sig_strike', 'B_Sig_strike', 'A_Takedowns', 'B_Takedowns',\n",
    "                'A_Sub_Attempts', 'B_Sub_Attempts', 'A_Ctrl_time', 'B_Ctrl_time']\n",
    "    totals.drop(columns=bad_cols, inplace=True)\n",
    "    totals.to_csv('data/ufc_stats/fight_totals2/' + fightid + '_totals.csv')\n",
    "    return totals\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_strikes(url):\n",
    "    df = pd.read_html(url)\n",
    "    # Part 2: Significant Strikes\n",
    "    ss = df[2]\n",
    "     \n",
    "    ss['Fighter_A'] = ss['Fighter'].str.split(' ').str[0] + ' ' + ss['Fighter'].str.split(' ').str[1]\n",
    "    ss['Fighter_B'] = ss['Fighter'].str.split(' ').str[2] + ' ' + ss['Fighter'].str.split(' ').str[3]\n",
    "    ss['A_Head_Strikes'] = ss['Head'].str.split('  ').str[0]\n",
    "    ss['B_Head_Strikes'] = ss['Head'].str.split('  ').str[1]\n",
    "    # split head strikes into landed and attempted\n",
    "    ss['A_Head_Strikes_land'] = ss['A_Head_Strikes'].str.split(' of ').str[0]\n",
    "    ss['A_Head_Strikes_att'] = ss['A_Head_Strikes'].str.split(' of ').str[1]\n",
    "    ss['B_Head_Strikes_land'] = ss['B_Head_Strikes'].str.split(' of ').str[0]\n",
    "    ss['B_Head_Strikes_att'] = ss['B_Head_Strikes'].str.split(' of ').str[1]\n",
    "    # change to numeric\n",
    "    ss['A_Head_Strikes_land'] = pd.to_numeric(ss['A_Head_Strikes_land'])\n",
    "    ss['A_Head_Strikes_att'] = pd.to_numeric(ss['A_Head_Strikes_att'])\n",
    "    ss['B_Head_Strikes_land'] = pd.to_numeric(ss['B_Head_Strikes_land'])\n",
    "    ss['B_Head_Strikes_att'] = pd.to_numeric(ss['B_Head_Strikes_att'])\n",
    "    # Head Strikes Percentage\n",
    "    ss['A_Head_Strikes_percent'] = ss['A_Head_Strikes_land'] / ss['A_Head_Strikes_att']\n",
    "    ss['B_Head_Strikes_percent'] = ss['B_Head_Strikes_land'] / ss['B_Head_Strikes_att']\n",
    "    # Body Strikes\n",
    "    ss['A_Body_Strikes'] = ss['Body'].str.split('  ').str[0]\n",
    "    ss['B_Body_Strikes'] = ss['Body'].str.split('  ').str[1]\n",
    "    # split body strikes into landed and attempted\n",
    "    ss['A_Body_Strikes_land'] = ss['A_Body_Strikes'].str.split(' of ').str[0]\n",
    "    ss['A_Body_Strikes_att'] = ss['A_Body_Strikes'].str.split(' of ').str[1]\n",
    "    ss['B_Body_Strikes_land'] = ss['B_Body_Strikes'].str.split(' of ').str[0]\n",
    "    ss['B_Body_Strikes_att'] = ss['B_Body_Strikes'].str.split(' of ').str[1]\n",
    "    # change to numeric\n",
    "    ss['A_Body_Strikes_land'] = pd.to_numeric(ss['A_Body_Strikes_land'])\n",
    "    ss['A_Body_Strikes_att'] = pd.to_numeric(ss['A_Body_Strikes_att'])\n",
    "    ss['B_Body_Strikes_land'] = pd.to_numeric(ss['B_Body_Strikes_land'])\n",
    "    ss['B_Body_Strikes_att'] = pd.to_numeric(ss['B_Body_Strikes_att'])\n",
    "    # Body Strikes Percentage\n",
    "    ss['A_Body_Strikes_percent'] = ss['A_Body_Strikes_land'] / ss['A_Body_Strikes_att']\n",
    "    ss['B_Body_Strikes_percent'] = ss['B_Body_Strikes_land'] / ss['B_Body_Strikes_att']\n",
    "    # Leg Strikes\n",
    "    ss['A_Leg_Strikes'] = ss['Leg'].str.split('  ').str[0]\n",
    "    ss['B_Leg_Strikes'] = ss['Leg'].str.split('  ').str[1]\n",
    "    # split leg strikes into landed and attempted\n",
    "    ss['A_Leg_Strikes_land'] = ss['A_Leg_Strikes'].str.split(' of ').str[0]\n",
    "    ss['A_Leg_Strikes_att'] = ss['A_Leg_Strikes'].str.split(' of ').str[1]\n",
    "    ss['B_Leg_Strikes_land'] = ss['B_Leg_Strikes'].str.split(' of ').str[0]\n",
    "    ss['B_Leg_Strikes_att'] = ss['B_Leg_Strikes'].str.split(' of ').str[1]\n",
    "    # change to numeric\n",
    "    ss['A_Leg_Strikes_land'] = pd.to_numeric(ss['A_Leg_Strikes_land'])\n",
    "    ss['A_Leg_Strikes_att'] = pd.to_numeric(ss['A_Leg_Strikes_att'])\n",
    "    ss['B_Leg_Strikes_land'] = pd.to_numeric(ss['B_Leg_Strikes_land'])\n",
    "    ss['B_Leg_Strikes_att'] = pd.to_numeric(ss['B_Leg_Strikes_att'])\n",
    "    # Leg Strikes Percentage\n",
    "    ss['A_Leg_Strikes_percent'] = ss['A_Leg_Strikes_land'] / ss['A_Leg_Strikes_att']\n",
    "    ss['B_Leg_Strikes_percent'] = ss['B_Leg_Strikes_land'] / ss['B_Leg_Strikes_att']\n",
    "    # Distance Strikes\n",
    "    ss['A_Distance_Strikes'] = ss['Distance'].str.split('  ').str[0]\n",
    "    ss['B_Distance_Strikes'] = ss['Distance'].str.split('  ').str[1]\n",
    "    # split distance strikes into landed and attempted\n",
    "    ss['A_Distance_Strikes_land'] = ss['A_Distance_Strikes'].str.split(' of ').str[0]\n",
    "    ss['A_Distance_Strikes_att'] = ss['A_Distance_Strikes'].str.split(' of ').str[1]\n",
    "    ss['B_Distance_Strikes_land'] = ss['B_Distance_Strikes'].str.split(' of ').str[0]\n",
    "    ss['B_Distance_Strikes_att'] = ss['B_Distance_Strikes'].str.split(' of ').str[1]\n",
    "    # change to numeric\n",
    "    ss['A_Distance_Strikes_land'] = pd.to_numeric(ss['A_Distance_Strikes_land'])\n",
    "    ss['A_Distance_Strikes_att'] = pd.to_numeric(ss['A_Distance_Strikes_att'])\n",
    "    ss['B_Distance_Strikes_land'] = pd.to_numeric(ss['B_Distance_Strikes_land'])\n",
    "    ss['B_Distance_Strikes_att'] = pd.to_numeric(ss['B_Distance_Strikes_att'])\n",
    "    # distance strikes percentage\n",
    "    ss['A_Distance_Strikes_percent'] = ss['A_Distance_Strikes_land'] / ss['A_Distance_Strikes_att']\n",
    "    ss['B_Distance_Strikes_percent'] = ss['B_Distance_Strikes_land'] / ss['B_Distance_Strikes_att']\n",
    "\n",
    "    # Clinch Strikes\n",
    "    ss['A_Clintch_Strikes'] = ss['Clinch'].str.split('  ').str[0]\n",
    "    ss['B_Clintch_Strikes'] = ss['Clinch'].str.split('  ').str[1]\n",
    "    # split clinch strikes into landed and attempted\n",
    "    ss['A_Clinch_Strikes_land'] = ss['A_Clintch_Strikes'].str.split(' of ').str[0]\n",
    "    ss['A_Clinch_Strikes_att'] = ss['A_Clintch_Strikes'].str.split(' of ').str[1]\n",
    "    ss['B_Clinch_Strikes_land'] = ss['B_Clintch_Strikes'].str.split(' of ').str[0]\n",
    "    ss['B_Clinch_Strikes_att'] = ss['B_Clintch_Strikes'].str.split(' of ').str[1]\n",
    "    # change to numeric\n",
    "    ss['A_Clinch_Strikes_land'] = pd.to_numeric(ss['A_Clinch_Strikes_land'])\n",
    "    ss['A_Clinch_Strikes_att'] = pd.to_numeric(ss['A_Clinch_Strikes_att'])\n",
    "    ss['B_Clinch_Strikes_land'] = pd.to_numeric(ss['B_Clinch_Strikes_land'])\n",
    "    ss['B_Clinch_Strikes_att'] = pd.to_numeric(ss['B_Clinch_Strikes_att'])\n",
    "    # clinch strikes percentage\n",
    "    ss['A_Clinch_Strikes_percent'] = ss['A_Clinch_Strikes_land'] / ss['A_Clinch_Strikes_att']\n",
    "    ss['B_Clinch_Strikes_percent'] = ss['B_Clinch_Strikes_land'] / ss['B_Clinch_Strikes_att']\n",
    "\n",
    "    # Ground Strikes\n",
    "    ss['A_Ground_Strikes'] = ss['Ground'].str.split('  ').str[0]\n",
    "    ss['B_Ground_Strikes'] = ss['Ground'].str.split('  ').str[1]\n",
    "    # split ground strikes into landed and attempted\n",
    "    ss['A_Ground_Strikes_land'] = ss['A_Ground_Strikes'].str.split(' of ').str[0]\n",
    "    ss['A_Ground_Strikes_att'] = ss['A_Ground_Strikes'].str.split(' of ').str[1]\n",
    "    ss['B_Ground_Strikes_land'] = ss['B_Ground_Strikes'].str.split(' of ').str[0]\n",
    "    ss['B_Ground_Strikes_att'] = ss['B_Ground_Strikes'].str.split(' of ').str[1]\n",
    "    # change to numeric\n",
    "    ss['A_Ground_Strikes_land'] = pd.to_numeric(ss['A_Ground_Strikes_land'])\n",
    "    ss['A_Ground_Strikes_att'] = pd.to_numeric(ss['A_Ground_Strikes_att'])\n",
    "    ss['B_Ground_Strikes_land'] = pd.to_numeric(ss['B_Ground_Strikes_land'])\n",
    "    ss['B_Ground_Strikes_att'] = pd.to_numeric(ss['B_Ground_Strikes_att'])\n",
    "    # ground strikes percentage\n",
    "    ss['A_Ground_Strikes_percent'] = ss['A_Ground_Strikes_land'] / ss['A_Ground_Strikes_att']\n",
    "    ss['B_Ground_Strikes_percent'] = ss['B_Ground_Strikes_land'] / ss['B_Ground_Strikes_att']\n",
    "    # add stuff with beautiful soup\n",
    "    ss['details'] = get_details_from_ufcstats(url)\n",
    "    ss['event_title'] = get_event_title_from_ufcstats(url)\n",
    "    event_url = get_event_url_from_ufcstats(url)\n",
    "    ss['event_url'] = event_url\n",
    "\n",
    "    fightid = url[url.find('fight-details/')+14:]\n",
    "\n",
    "    bad_cols = ['Fighter', 'Sig. str', 'Sig. str. %', 'Head', 'Body', 'Leg', 'Distance', 'Clinch', 'Ground',\n",
    "                'A_Head_Strikes', 'B_Head_Strikes', 'A_Body_Strikes', 'B_Body_Strikes', 'A_Leg_Strikes', 'B_Leg_Strikes',\n",
    "                'A_Distance_Strikes', 'B_Distance_Strikes', 'A_Clintch_Strikes', 'B_Clintch_Strikes', 'A_Ground_Strikes', \n",
    "                'B_Ground_Strikes']\n",
    "    ss.drop(columns=bad_cols, inplace=True)\n",
    "    ss.to_csv('data/ufc_stats/sig_strikes2/' + fightid + '_sigstrikes.csv')\n",
    "\n",
    "    return ss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Event Data (check against files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all_event_data\n",
    "all_event_data = pd.read_csv('data/final/events/All_Events_Fights_and_FightUrls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493\n"
     ]
    }
   ],
   "source": [
    "inital_events_chosen = all_event_data['event_id'].unique()\n",
    "print(len(inital_events_chosen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inital_events_chosen = inital_events_chosen.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_events():\n",
    "    ufc_stats_events = \"http://ufcstats.com/statistics/events/completed?page=all\"\n",
    "\n",
    "    # for each event, get the event link\n",
    "    page = requests.get(ufc_stats_events)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    event_linkies = soup.find_all('a', class_='b-link b-link_style_black')\n",
    "\n",
    "    # list of event links and event titles\n",
    "    event_links = [n['href'] for n in event_linkies]\n",
    "    event_titles = [n.text for n in event_linkies]\n",
    "    # replace '\\n' with ''\n",
    "    event_titles = [n.replace('\\n', '').strip() for n in event_titles]\n",
    "\n",
    "    # make df\n",
    "    event_df = pd.DataFrame({'event_title': event_titles, 'event_url': event_links})\n",
    "    # take most recent 5\n",
    "    ed = event_df.head(5)\n",
    "\n",
    "    # return 5 most recent\n",
    "    return ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_title</th>\n",
       "      <th>event_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UFC Fight Night: Vera vs. Sandhagen</td>\n",
       "      <td>http://ufcstats.com/event-details/aec273fcb765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UFC 286: Edwards vs. Usman 3</td>\n",
       "      <td>http://ufcstats.com/event-details/e4bb7e483c4a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UFC Fight Night: Yan vs. Dvalishvili</td>\n",
       "      <td>http://ufcstats.com/event-details/35080a7f406f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UFC 285: Jones vs. Gane</td>\n",
       "      <td>http://ufcstats.com/event-details/1ccff7f0cfdf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UFC Fight Night: Muniz vs. Allen</td>\n",
       "      <td>http://ufcstats.com/event-details/806975e1b4f4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            event_title  \\\n",
       "0   UFC Fight Night: Vera vs. Sandhagen   \n",
       "1          UFC 286: Edwards vs. Usman 3   \n",
       "2  UFC Fight Night: Yan vs. Dvalishvili   \n",
       "3               UFC 285: Jones vs. Gane   \n",
       "4      UFC Fight Night: Muniz vs. Allen   \n",
       "\n",
       "                                           event_url  \n",
       "0  http://ufcstats.com/event-details/aec273fcb765...  \n",
       "1  http://ufcstats.com/event-details/e4bb7e483c4a...  \n",
       "2  http://ufcstats.com/event-details/35080a7f406f...  \n",
       "3  http://ufcstats.com/event-details/1ccff7f0cfdf...  \n",
       "4  http://ufcstats.com/event-details/806975e1b4f4...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_recent_events = get_most_recent_events()\n",
    "most_recent_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add event_id\n",
    "most_recent_events['event_id'] = most_recent_events['event_url'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_ufcstats_event_ids = most_recent_events['event_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_missing_events(completed_ufcstats_event_ids):\n",
    "    \n",
    "    # check the list of completed events against the events2 folder\n",
    "    # make list of events that are no downloading\n",
    "\n",
    "    missing = []\n",
    "    for event in completed_ufcstats_event_ids:\n",
    "        if event + '.csv' not in os.listdir('data/ufc_stats/events2'):\n",
    "            missing.append(event)\n",
    "\n",
    "    return missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aec273fcb765330d']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_events = check_for_missing_events(completed_ufcstats_event_ids)\n",
    "missing_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just this one time\n",
    "missing_events = missing_events[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update by downloading events\n",
    "for event in missing_events:\n",
    "    get_event_details(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each missing event, download all fights data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ufcstats_fight_urls(missing_event_df):\n",
    "\n",
    "    # For each missing event, download the fight url links\n",
    "\n",
    "    links = pd.DataFrame()\n",
    "    for event in missing_event_df:\n",
    "        data = pd.read_csv('data/ufc_stats/events2/'+ event +'.csv')\n",
    "        links = links.append(data[['Fighter1', 'Fighter2','fight_link', 'event_id']], ignore_index=True)\n",
    "    return links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_fights = get_ufcstats_fight_urls(missing_events)\n",
    "missing_fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing fights\n"
     ]
    }
   ],
   "source": [
    "if len(missing_fights) > 0:\n",
    "    missing_fight_links = missing_fights['fight_link'].tolist()\n",
    "    for fight_link in missing_fight_links:\n",
    "        \n",
    "        # get totals\n",
    "        get_fight_totals(fight_link)\n",
    "        get_significant_strikes(fight_link)\n",
    "\n",
    "else:\n",
    "    print('No missing fights')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update for NEXT Fight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the next 3 UFC events using BeautifulSoup\n",
    "def get_next_events(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # get events\n",
    "    event1 = soup.find('div', class_='c-card-event--result__info')\n",
    "    event1_txt = soup.find('div', class_='c-card-event--result__info').text\n",
    "    event1_url = event1.find('a')['href']\n",
    "    event1_url = 'https://www.ufc.com' + event1_url\n",
    "    event1_title = event1_txt.split('\\n')[1]\n",
    "    event1_time = event1_txt.split('/')[1]\n",
    "\n",
    "    data = pd.DataFrame({'event_title': [event1_title], 'event_url': [event1_url], 'event_date': [event1_time]})\n",
    "\n",
    "    event2 = soup.find('div', class_='c-card-event--result__info').find_next('div', class_='c-card-event--result__info')\n",
    "    event2_txt = soup.find('div', class_='c-card-event--result__info').find_next('div', class_='c-card-event--result__info').text\n",
    "    event2_url = event2.find('a')['href']\n",
    "    event2_url = 'https://www.ufc.com' + event2_url\n",
    "    event2_title = event2_txt.split('\\n')[1]\n",
    "    event2_time = event2_txt.split('/')[1]\n",
    "\n",
    "\n",
    "    data = data.append({'event_title': event2_title, 'event_url': event2_url, 'event_date': event2_time}, ignore_index=True)\n",
    "    \n",
    "    event3 = soup.find('div', class_='c-card-event--result__info').find_next('div', class_='c-card-event--result__info').find_next('div', class_='c-card-event--result__info')\n",
    "    event3_txt = soup.find('div', class_='c-card-event--result__info').find_next('div', class_='c-card-event--result__info').find_next('div', class_='c-card-event--result__info').text\n",
    "    event3_url = event3.find('a')['href']\n",
    "    event3_url = 'https://www.ufc.com' + event3_url\n",
    "    event3_title = event3_txt.split('\\n')[1]\n",
    "    event3_time = event3_txt.split('/')[1]\n",
    "\n",
    "    data = data.append({'event_title': event3_title, 'event_url': event3_url, 'event_date': event3_time}, ignore_index=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Function to get the fight card for a given event using BeautifulSoup\n",
    "def get_event_fights(event_url):\n",
    "    page = requests.get(event_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # get main card, fight 1\n",
    "\n",
    "    mcn = soup.find_all('li', class_='l-listing__item')\n",
    "    # get num of mc\n",
    "    num_mc = len(mcn)\n",
    "    # for each mc, do the following\n",
    "    data = pd.DataFrame()\n",
    "    n = 0\n",
    "    for i in mcn:\n",
    "        mc = mcn[n]\n",
    "        # fight 1\n",
    "        fighter1= mc.find('div', class_ ='c-listing-fight__corner-name c-listing-fight__corner-name--red').text\n",
    "        fighter1 = fighter1.replace('\\n', ' ')\n",
    "        fighter1 = fighter1.strip()\n",
    "        fighter2 = mc.find('div', class_ ='c-listing-fight__corner-name c-listing-fight__corner-name--blue').text\n",
    "        fighter2 = fighter2.replace('\\n', ' ')\n",
    "        fighter2 = fighter2.strip()\n",
    "        weightclass = mc.find('div', class_='c-listing-fight__class-text').text\n",
    "        fighter1_odds = mc.find('span', class_='c-listing-fight__odds').text\n",
    "        fighter2_odds = mc.find('span', class_='c-listing-fight__odds').find_next('span', class_='c-listing-fight__odds').text\n",
    "        fighter1_odds = fighter1_odds.replace('\\n', '')\n",
    "        fighter2_odds = fighter2_odds.replace('\\n', '')\n",
    "        # fighter odds to float\n",
    "        if (fighter1_odds == '-') :\n",
    "            fighter1_odds = nan\n",
    "        if (fighter2_odds == '-') :\n",
    "            fighter2_odds = nan\n",
    "\n",
    "        data = data.append({'fighter1': fighter1, 'fighter2': fighter2, 'weightclass': weightclass, \n",
    "                            'fighter1_odds': fighter1_odds, 'fighter2_odds': fighter2_odds}, ignore_index=True)\n",
    "        n = n + 1\n",
    "    return data\n",
    "\n",
    "\n",
    "# get next events if event fighter data is not na\n",
    "def get_next_events2(url):\n",
    "    data = get_next_events(url)\n",
    "    for i in range(0, len(data)):\n",
    "        event_url = data['event_url'][i]\n",
    "        event_fights = get_event_fights(event_url)\n",
    "        if (len(event_fights) == 0):\n",
    "            data = data.drop(i)\n",
    "    return data\n",
    "\n",
    "# get next events from UFCStats.com using BS\n",
    "def get_next_event_ufcstats():\n",
    "    url = 'http://www.ufcstats.com/statistics/events/upcoming'\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # get events\n",
    "    event1 = soup.find('td', class_='b-statistics__table-col')\n",
    "    event1_txt = soup.find('td', class_='b-statistics__table-col').text\n",
    "    event_txt = event1_txt.replace('   ', '').replace('\\n', '').strip()\n",
    "    event_title = event_txt.split('  ')[0]\n",
    "    event_date = event_txt.split('  ')[1]\n",
    "    event1_url = event1.find('a')['href']\n",
    "    data = pd.DataFrame({'event_title': [event_title], 'event_url': [event1_url], 'event_date': [event_date]})\n",
    "    return data\n",
    "\n",
    "\n",
    "# get fighter urls from UFCStats.com using BS\n",
    "def get_fighter_urls(event_details_url):\n",
    "    page = requests.get(event_details_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # get events\n",
    "    events = soup.find_all('tr', class_='b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click')\n",
    "    n = 0\n",
    "    next_event_data = pd.DataFrame()\n",
    "\n",
    "    for event in events:\n",
    "        fighters = events[n].find_all('p', class_='b-fight-details__table-text')\n",
    "        fighter1 = fighters[0].text\n",
    "        fighter1 = fighter1.replace('  ', '').replace('\\n', '').strip()\n",
    "        fighter2 = fighters[1].text\n",
    "        fighter2 = fighter2.replace('  ', '').replace('\\n', '').strip()\n",
    "        fighter1_url = fighters[0].find('a')['href']\n",
    "        fighter2_url = fighters[1].find('a')['href']\n",
    "        next_event_data = next_event_data.append({'fighter1' :fighter1, 'fighter2:' : fighter2, 'fighter1_url': fighter1_url, 'fighter2_url':fighter2_url, 'fight#' : n+1}, ignore_index = True)\n",
    "        n += 1\n",
    "\n",
    "    return next_event_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_title</th>\n",
       "      <th>event_url</th>\n",
       "      <th>event_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pereira vs Adesanya 2</td>\n",
       "      <td>https://www.ufc.com/event/ufc-287</td>\n",
       "      <td>10:00 PM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holloway vs Allen</td>\n",
       "      <td>https://www.ufc.com/event/ufc-fight-night-apri...</td>\n",
       "      <td>8:30 PM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pavlovich vs Blaydes</td>\n",
       "      <td>https://www.ufc.com/event/ufc-fight-night-apri...</td>\n",
       "      <td>7:00 PM EDT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             event_title                                          event_url  \\\n",
       "0  Pereira vs Adesanya 2                  https://www.ufc.com/event/ufc-287   \n",
       "1      Holloway vs Allen  https://www.ufc.com/event/ufc-fight-night-apri...   \n",
       "2   Pavlovich vs Blaydes  https://www.ufc.com/event/ufc-fight-night-apri...   \n",
       "\n",
       "       event_date  \n",
       "0   10:00 PM EDT   \n",
       "1    8:30 PM EDT   \n",
       "2    7:00 PM EDT   "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_ufc_events = get_next_events('https://www.ufc.com/events')\n",
    "next_ufc_events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get event Fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fighter1</th>\n",
       "      <th>fighter2</th>\n",
       "      <th>weightclass</th>\n",
       "      <th>fighter1_odds</th>\n",
       "      <th>fighter2_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Israel Adesanya</td>\n",
       "      <td>Middleweight Title Bout</td>\n",
       "      <td>+115</td>\n",
       "      <td>-135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gilbert Burns</td>\n",
       "      <td>Jorge Masvidal</td>\n",
       "      <td>Welterweight Bout</td>\n",
       "      <td>-490</td>\n",
       "      <td>+390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rob Font</td>\n",
       "      <td>Adrian Yanez</td>\n",
       "      <td>Bantamweight Bout</td>\n",
       "      <td>+155</td>\n",
       "      <td>-180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>Santiago Ponzinibbio</td>\n",
       "      <td>Welterweight Bout</td>\n",
       "      <td>-250</td>\n",
       "      <td>+210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raul Rosas Jr.</td>\n",
       "      <td>Christian Rodriguez</td>\n",
       "      <td>Bantamweight Bout</td>\n",
       "      <td>-230</td>\n",
       "      <td>+195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chris Curtis</td>\n",
       "      <td>Kelvin Gastelum</td>\n",
       "      <td>Middleweight Bout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Michelle Waterson-Gomez</td>\n",
       "      <td>Luana Pinheiro</td>\n",
       "      <td>Women's Strawweight Bout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gerald Meerschaert</td>\n",
       "      <td>Joe Pyfer</td>\n",
       "      <td>Middleweight Bout</td>\n",
       "      <td>+160</td>\n",
       "      <td>-190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Karl Williams</td>\n",
       "      <td>Chase Sherman</td>\n",
       "      <td>Heavyweight Bout</td>\n",
       "      <td>+190</td>\n",
       "      <td>-225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cynthia Calvillo</td>\n",
       "      <td>Loopy Godinez</td>\n",
       "      <td>Women's Strawweight Bout</td>\n",
       "      <td>+210</td>\n",
       "      <td>-250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ignacio Bahamondes</td>\n",
       "      <td>Trey Ogden</td>\n",
       "      <td>Catchweight Bout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shayilan Nuerdanbieke</td>\n",
       "      <td>Steve Garcia</td>\n",
       "      <td>Featherweight Bout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jaqueline Amorim</td>\n",
       "      <td>Sam Hughes</td>\n",
       "      <td>Women's Strawweight Bout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fighter1              fighter2               weightclass  \\\n",
       "0              Alex Pereira       Israel Adesanya   Middleweight Title Bout   \n",
       "1             Gilbert Burns        Jorge Masvidal         Welterweight Bout   \n",
       "2                  Rob Font          Adrian Yanez         Bantamweight Bout   \n",
       "3             Kevin Holland  Santiago Ponzinibbio         Welterweight Bout   \n",
       "4            Raul Rosas Jr.   Christian Rodriguez         Bantamweight Bout   \n",
       "5              Chris Curtis       Kelvin Gastelum         Middleweight Bout   \n",
       "6   Michelle Waterson-Gomez        Luana Pinheiro  Women's Strawweight Bout   \n",
       "7        Gerald Meerschaert             Joe Pyfer         Middleweight Bout   \n",
       "8             Karl Williams         Chase Sherman          Heavyweight Bout   \n",
       "9          Cynthia Calvillo         Loopy Godinez  Women's Strawweight Bout   \n",
       "10       Ignacio Bahamondes            Trey Ogden          Catchweight Bout   \n",
       "11    Shayilan Nuerdanbieke          Steve Garcia        Featherweight Bout   \n",
       "12         Jaqueline Amorim            Sam Hughes  Women's Strawweight Bout   \n",
       "\n",
       "   fighter1_odds fighter2_odds  \n",
       "0           +115          -135  \n",
       "1           -490          +390  \n",
       "2           +155          -180  \n",
       "3           -250          +210  \n",
       "4           -230          +195  \n",
       "5            NaN           NaN  \n",
       "6            NaN           NaN  \n",
       "7           +160          -190  \n",
       "8           +190          -225  \n",
       "9           +210          -250  \n",
       "10           NaN           NaN  \n",
       "11           NaN           NaN  \n",
       "12           NaN           NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get event fights for first event\n",
    "event_url = next_ufc_events['event_url'][0]\n",
    "event_fights = get_event_fights(event_url)\n",
    "event_fights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get secret number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find secret number in ufc events using BS & Selenium\n",
    "def get_secret_number(event_url):\n",
    "    # if no driver open, open one\n",
    "    driver = None\n",
    "    if (driver == None):\n",
    "        driver = webdriver.Chrome('C:\\\\Users\\\\Travis\\\\OneDrive\\\\Data Science\\\\Personal_Projects\\\\Sports\\\\UFC_Prediction_V2\\\\chromedriver.exe')\n",
    "    \n",
    "    driver.get(event_url)\n",
    "    # sleep for 15 seconds\n",
    "    time.sleep(5)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    pretty = soup.prettify()\n",
    "\n",
    "    # find first data-fmid to get first matchup\n",
    "    fmid_start = pretty.find('data-fmid')\n",
    "    fmid = pretty[fmid_start+11:fmid_start+16]\n",
    "\n",
    "    # go to event url with fmid\n",
    "    driver.get(event_url +'#' + fmid)\n",
    "    time.sleep(8)\n",
    "\n",
    "    # find all links within page\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    # find all iframe src\n",
    "    iframe = soup.find_all('iframe')\n",
    "\n",
    "    # find all links\n",
    "    iframe_text = str(iframe)\n",
    "    matchup = iframe_text.find('matchup')\n",
    "    # matchup_url = iframe_text[matchup+8:matchup+12]\n",
    "    # print('matchup_url: ' + matchup_url)\n",
    "    # secret_number = matchup_url\n",
    "    return matchup, fmid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret_number_1: 684\n",
      "fmid_1: 10377\n"
     ]
    }
   ],
   "source": [
    "secret_number_1, fmid_1 = get_secret_number(event_url)\n",
    "print('secret_number_1: ' + str(secret_number_1))\n",
    "print('fmid_1: ' + str(fmid_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ufc.com/matchup/' + str(secret_number_1) + '/' + str(fmid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_get_soup(matchup_url):\n",
    "    response = requests.get(matchup_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get matchup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_soup(match_url):\n",
    "    # if no driver open, open one\n",
    "    driver = None\n",
    "    if (driver == None):\n",
    "        driver = webdriver.Chrome('C:\\\\Users\\\\Travis\\\\OneDrive\\\\Data Science\\\\Personal_Projects\\\\Sports\\\\UFC_Prediction_V2\\\\chromedriver.exe')\n",
    "    \n",
    "    driver.get(match_url)\n",
    "    # sleep for 5 seconds\n",
    "    time.sleep(5)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    # find class=\"c-listing-fight__details-content details-content\"\n",
    "\n",
    "    #chosen_fight = soup.find('div', class_='c-listing-fight__details-content details-content')\n",
    "    \n",
    "    # get inner html\n",
    "    inner_html = driver.execute_script(\"return document.body.innerHTML\")\n",
    "    chosen_fight = inner_html.find('c-listing-fight__details-content details-content')\n",
    "    chosen_fight = inner_html[chosen_fight:chosen_fight+1000]\n",
    "\n",
    "\n",
    "    # prettify inner html\n",
    "    soup2 = BeautifulSoup(inner_html, 'html.parser')\n",
    "    pretty = soup2.prettify()\n",
    "\n",
    "\n",
    "    return chosen_fight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape UFC fight data\n",
    "def grab_matchup_data(matchup_url):\n",
    "    response = requests.get(matchup_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser').text\n",
    "    soup = soup.replace('   ', '').replace('\\n', '')\n",
    "\n",
    "    od = soup.find('Odds')\n",
    "    rec = soup.find('Record')\n",
    "    a_record = soup[od + 5 : rec - 2]\n",
    "    last_fight = soup.find(\"Last Fight\")\n",
    "    b_record = soup[rec + 7 : last_fight - 5]\n",
    "\n",
    "    hite = soup.find('Height')\n",
    "    f = soup.find(\"' \")\n",
    "    a_height = soup[f -1 : hite - 2]\n",
    "    # find second occurance of f\n",
    "    f2 = soup.find(\"' \", f + 1)\n",
    "    b_height = soup[hite + 7 : f2+5]\n",
    "\n",
    "    # Find reach\n",
    "    reach = soup.find('Reach')\n",
    "    # find second occurance of \"LB\"\n",
    "    lb = soup.find('LB')\n",
    "    lb2 = soup.find('LB', lb + 1)\n",
    "    a_reach = soup[lb2 +5 : reach ]\n",
    "    inn = soup.find(\"in \")\n",
    "    # get the word after reach\n",
    "    big_space = soup.find('  ', reach + 1)\n",
    "    b_reach = soup[reach + 6 : big_space]\n",
    "\n",
    "    # Find Leg Reach\n",
    "    leg = soup.find('Leg Reach')\n",
    "    big_space2 = soup.find('  ', big_space + 1)\n",
    "    a_leg = soup[big_space2 + 2 : leg]\n",
    "    big_space4 = soup.find('  ', big_space2 + 2)\n",
    "    b_leg = soup[leg + 10 : leg + 17]\n",
    "\n",
    "    a_record = a_record.strip()\n",
    "    b_record = b_record.strip()\n",
    "\n",
    "    a_height_ft = float(a_height[:1])\n",
    "    a_height_in = float(a_height[3:].replace(\"'\", \"\").replace('\"', ''))\n",
    "    a_height = (a_height_ft * 12) + a_height_in \n",
    "\n",
    "\n",
    "    b_height_ft = float(b_height[:1])\n",
    "    b_height_in = float(b_height[3:].replace(\"'\", \"\").replace('\"', ''))\n",
    "    b_height = (b_height_ft * 12) + b_height_in\n",
    "\n",
    "    a_reach = float(a_reach.replace(' in', '').strip())\n",
    "    b_reach = float(b_reach.replace(' in', '').strip())\n",
    "\n",
    "    a_leg = float(a_leg.replace(' in', '').strip())\n",
    "    b_leg = float(b_leg.replace(' in', '').strip())\n",
    "\n",
    "    \n",
    "    return a_record, b_record, a_height, b_height, a_reach, b_reach, a_leg, b_leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Travis\\OneDrive\\Data Science\\Personal_Projects\\Sports\\UFC_Prediction_V2\\V2_Newer_Notebooks\\9a. Updating UfcStats.ipynb Cell 39\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Travis/OneDrive/Data%20Science/Personal_Projects/Sports/UFC_Prediction_V2/V2_Newer_Notebooks/9a.%20Updating%20UfcStats.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# test\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Travis/OneDrive/Data%20Science/Personal_Projects/Sports/UFC_Prediction_V2/V2_Newer_Notebooks/9a.%20Updating%20UfcStats.ipynb#Y100sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m matchup_url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://www.ufc.com/event/ufc-287#10377\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Travis/OneDrive/Data%20Science/Personal_Projects/Sports/UFC_Prediction_V2/V2_Newer_Notebooks/9a.%20Updating%20UfcStats.ipynb#Y100sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m a_record, b_record, a_height, b_height, a_reach, b_reach, a_leg, b_leg \u001b[39m=\u001b[39m grab_matchup_data(matchup_url)\n",
      "\u001b[1;32mc:\\Users\\Travis\\OneDrive\\Data Science\\Personal_Projects\\Sports\\UFC_Prediction_V2\\V2_Newer_Notebooks\\9a. Updating UfcStats.ipynb Cell 39\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Travis/OneDrive/Data%20Science/Personal_Projects/Sports/UFC_Prediction_V2/V2_Newer_Notebooks/9a.%20Updating%20UfcStats.ipynb#Y100sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m a_record \u001b[39m=\u001b[39m a_record\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Travis/OneDrive/Data%20Science/Personal_Projects/Sports/UFC_Prediction_V2/V2_Newer_Notebooks/9a.%20Updating%20UfcStats.ipynb#Y100sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m b_record \u001b[39m=\u001b[39m b_record\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Travis/OneDrive/Data%20Science/Personal_Projects/Sports/UFC_Prediction_V2/V2_Newer_Notebooks/9a.%20Updating%20UfcStats.ipynb#Y100sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m a_height_ft \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(a_height[:\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Travis/OneDrive/Data%20Science/Personal_Projects/Sports/UFC_Prediction_V2/V2_Newer_Notebooks/9a.%20Updating%20UfcStats.ipynb#Y100sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m a_height_in \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(a_height[\u001b[39m3\u001b[39m:]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Travis/OneDrive/Data%20Science/Personal_Projects/Sports/UFC_Prediction_V2/V2_Newer_Notebooks/9a.%20Updating%20UfcStats.ipynb#Y100sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m a_height \u001b[39m=\u001b[39m (a_height_ft \u001b[39m*\u001b[39m \u001b[39m12\u001b[39m) \u001b[39m+\u001b[39m a_height_in \n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "# test\n",
    "matchup_url = 'https://www.ufc.com/event/ufc-287#10377'\n",
    "a_record, b_record, a_height, b_height, a_reach, b_reach, a_leg, b_leg = grab_matchup_data(matchup_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Trav310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f69e36f0e9b2c8d9f319b417484f14b77c91d7bef950ad448542405eb1e0e594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
